# ML System Design Document: BankShield

**Дата создания:** 22 декабря 2025  
**Авторы:** Команда BankShield  

---

## Содержание

1. [Общая информация](#1-общая-информация)
2. [Постановка бизнес-задачи](#2-постановка-бизнес-задачи)
3. [Постановка технической задачи](#3-постановка-технической-задачи)
4. [Продуктивизация проекта](#4-продуктивизация-проекта)
5. [Масштабирование и развитие](#5-масштабирование-и-развитие)
6. [Нагрузочное тестирование](#6-нагрузочное-тестирование)

---

> 📊 **Визуализация архитектуры**: Все диаграммы системы доступны в отдельном документе [ARCHITECTURE_DIAGRAMS.md](ARCHITECTURE_DIAGRAMS.md)
> 
> Включает 10 детальных диаграмм в формате Mermaid:
> - Общая архитектура системы
> - Поток данных (Data Flow)
> - DBT трансформации (Layered Architecture)
> - Airflow DAGs
> - Компоненты и их взаимодействие
> - Масштабирование архитектуры
> - Deployment Architecture
> - API Request Flow
> - Data Quality Monitoring Flow
> - Future Architecture (с ML и Real-time)

---

## 1. Общая информация

### 1.1 Бизнес-цель проекта

**BankShield** — система анализа банковских транзакций в реальном времени для выявления аномалий и мошеннических операций.

#### Проблема
Банки и финансовые организации ежедневно обрабатывают миллионы транзакций. Мошеннические операции приводят к финансовым потерям как для клиентов, так и для банков. Для качественного мониторинга необходимо обрабатывать большой объем данных и обеспечивать анализ в реальном времени.

#### Потребности бизнеса
- **Снижение финансовых потерь** от мошеннических операций
- **Повышение доверия клиентов** через защиту их средств
- **Соответствие регуляторным требованиям** (AML, KYC, PCI DSS)
- **Оптимизация операционных расходов** на мониторинг транзакций
- **Аналитика в реальном времени** для принятия бизнес-решений

#### Что считается успехом проекта
- Система обрабатывает транзакции с задержкой не более **10 секунд** при нагрузке **1 RPM**
- Доступность сервиса **99.5%** времени
- Выявление **≥95%** мошеннических транзакций
- Снижение количества ложных срабатываний на **30%**
- Масштабируемость до **1000 транзакций в минуту**

---

## 2. Постановка бизнес-задачи

### 2.1 Бизнес-требования

#### Функциональные требования
1. **Сбор данных о транзакциях**
   - Интеграция с операционными системами банка
   - Сохранение всех атрибутов транзакций (сумма, валюта, геолокация, устройство)
   - Поддержка различных типов транзакций (дебет, кредит, переводы, снятие, депозит)

2. **Анализ транзакций**
   - Вычисление риск-скора для каждой транзакции (0-1)
   - Классификация транзакций по категориям риска
   - Агрегация метрик по пользователям и временным периодам

3. **Визуализация и отчетность**
   - Дашборды для мониторинга в реальном времени
   - Отчеты по мошенничеству (дневные, недельные, месячные)
   - Аналитика по категориям мерчантов и географии

4. **API для интеграции**
   - REST API для генерации и получения транзакций
   - Endpoints для статистики и мониторинга
   - Автодокументация (Swagger/OpenAPI)

#### Нефункциональные требования
- **Производительность**: время отклика API ≤ 10 секунд при 1 RPM
- **Доступность**: 99.5% uptime
- **Масштабируемость**: поддержка роста нагрузки до 1000 RPM
- **Безопасность**: защита персональных данных, аудит действий
- **Надежность**: отказоустойчивость компонентов

### 2.2 Критерии успеха проекта

| Метрика | Целевое значение | Способ измерения |
|---------|------------------|------------------|
| Время отклика API | ≤ 10 сек при 1 RPM | Мониторинг через Grafana |
| Доступность сервиса | ≥ 99.5% | Uptime monitoring |
| Точность выявления фрода | ≥ 95% | Precision/Recall на тестовых данных |
| Ложные срабатывания | Снижение на 30% | False Positive Rate |
| Пропускная способность | До 1000 RPM | Нагрузочное тестирование |
| Задержка обработки данных | ≤ 1 час | Мониторинг Airflow DAGs |

### 2.3 Типичный Use Case

#### Сценарий 1: Обработка транзакции в реальном времени

1. **Актор**: Банковское приложение клиента
2. **Предусловие**: Клиент инициирует транзакцию (перевод средств)
3. **Основной поток**:
   - Банковское приложение отправляет данные транзакции в MongoDB
   - Data Collector сохраняет транзакцию с timestamp
   - Airflow EL DAG извлекает новые транзакции каждые 30 минут
   - DBT трансформирует данные через слои (STG → ODS → DWH → DM)
   - Grafana отображает обновленные метрики на дашборде
   - Аналитик видит транзакцию и ее риск-скор
4. **Результат**: Транзакция обработана, риск-скор вычислен, данные доступны для анализа

#### Сценарий 2: Анализ мошенничества через API

1. **Актор**: Внешняя система мониторинга
2. **Предусловие**: Система имеет доступ к BankShield API
3. **Основной поток**:
   - Система отправляет GET запрос к `/transactions/stats`
   - API возвращает агрегированную статистику (fraud_rate, total_amount)
   - Система анализирует метрики и принимает решения
   - При превышении порога fraud_rate система отправляет алерт
4. **Результат**: Своевременное обнаружение аномалий

#### Сценарий 3: Генерация тестовых данных

1. **Актор**: QA инженер
2. **Предусловие**: Необходимо протестировать систему
3. **Основной поток**:
   - QA отправляет POST запрос к `/transactions/batch?count=100`
   - API генерирует 100 синтетических транзакций
   - Транзакции сохраняются в MongoDB
   - EL процесс переносит их в PostgreSQL
   - DBT обрабатывает новые данные
4. **Результат**: Система протестирована на реалистичных данных

---

## 3. Постановка технической задачи

### 3.1 Формулировка задачи

**Цель**: Разработать и внедрить систему сбора, обработки и анализа банковских транзакций с автоматическим вычислением риск-скоров и выявлением мошеннических операций.

**Техническая задача**:
1. Создать генератор синтетических транзакций для демонстрации и тестирования
2. Реализовать ELT-пайплайн для переноса данных из операционной БД в аналитическую
3. Построить многослойную архитектуру трансформации данных (STG → ODS → DWH → DM)
4. Разработать REST API для интеграции с внешними системами
5. Создать дашборды для визуализации метрик в реальном времени
6. Настроить мониторинг качества данных

### 3.2 Метрики качества решения

#### Технические метрики

| Метрика | Описание | Способ расчета | Целевое значение |
|---------|----------|----------------|------------------|
| **API Response Time** | Время отклика API | p95 latency через Grafana | ≤ 10 сек |
| **Data Freshness** | Свежесть данных | Разница между timestamp транзакции и временем в DM | ≤ 1 час |
| **ETL Success Rate** | Успешность ETL процессов | (Успешные runs / Всего runs) × 100% | ≥ 99% |
| **Data Quality Score** | Качество данных | Elementary anomaly detection | ≥ 95% |
| **System Uptime** | Доступность системы | Uptime monitoring | ≥ 99.5% |

#### Бизнес-метрики

| Бизнес-метрика | Техническая метрика | Связь |
|----------------|---------------------|-------|
| Снижение потерь от фрода | Fraud Detection Rate | Выявление 95% мошеннических транзакций |
| Удовлетворенность клиентов | False Positive Rate | Снижение ложных блокировок на 30% |
| Операционная эффективность | ETL Success Rate | Автоматизация обработки данных |
| Скорость реакции на инциденты | Data Freshness | Данные доступны в течение 1 часа |

### 3.3 Данные для решения задачи

#### 3.3.1 Источники данных

**Операционная база данных (MongoDB)**
- **Назначение**: Хранение транзакций в реальном времени
- **Объем**: ~10,000 транзакций в день (тестовая среда)
- **Обновление**: Непрерывно (каждые 60 секунд новая транзакция)
- **Доступ**: MongoDB connection string

#### 3.3.2 Структура данных транзакции

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "transaction_id": "TXN123456",
  "user_id": "USER1234",
  "amount": 150.50,
  "currency": "USD",
  "transaction_type": "debit",
  "merchant_category": "grocery",
  "merchant_name": "Merchant_42",
  "location": {
    "country": "USA",
    "city": "New York",
    "latitude": 40.7128,
    "longitude": -74.0060
  },
  "device_info": {
    "device_type": "mobile",
    "os": "iOS",
    "ip_address": "192.168.1.1"
  },
  "is_fraud": false,
  "risk_score": 0.234,
  "metadata": {
    "session_id": "SESS12345",
    "user_agent": "Mozilla/5.0..."
  }
}
```

#### 3.3.3 Описание полей

| Поле | Тип | Описание | Обязательное |
|------|-----|----------|--------------|
| `timestamp` | DateTime | Время транзакции (UTC) | Да |
| `transaction_id` | String | Уникальный ID транзакции | Да |
| `user_id` | String | ID пользователя | Да |
| `amount` | Float | Сумма транзакции | Да |
| `currency` | String | Валюта (USD, EUR, RUB) | Да |
| `transaction_type` | String | Тип (debit, credit, transfer, withdrawal, deposit) | Да |
| `merchant_category` | String | Категория мерчанта | Да |
| `merchant_name` | String | Название мерчанта | Да |
| `location` | Object | Геолокация транзакции | Да |
| `device_info` | Object | Информация об устройстве | Да |
| `is_fraud` | Boolean | Флаг мошенничества | Да |
| `risk_score` | Float | Риск-скор (0-1) | Да |
| `metadata` | Object | Дополнительные метаданные | Нет |

#### 3.3.4 Результаты EDA (Exploratory Data Analysis)

**Распределение транзакций по типам**:
- Debit: 35%
- Credit: 25%
- Transfer: 20%
- Withdrawal: 12%
- Deposit: 8%

**Распределение по валютам**:
- USD: 60%
- EUR: 25%
- RUB: 15%

**Статистика мошенничества**:
- Fraud rate: ~5% (реалистичное значение для финансовой индустрии)
- Средний риск-скор для легитимных транзакций: 0.15-0.30
- Средний риск-скор для мошеннических транзакций: 0.70-0.95

**Категории мерчантов** (топ-5):
1. Online (30%)
2. Grocery (20%)
3. Restaurants (15%)
4. Gas stations (12%)
5. Entertainment (10%)

**Географическое распределение**:
- USA: 40%
- Europe: 35%
- Russia: 15%
- Other: 10%

### 3.4 Архитектура решения

> 📊 **См. также**: [Архитектурные диаграммы](ARCHITECTURE_DIAGRAMS.md) - детальные диаграммы в формате Mermaid

#### 3.4.1 Общая архитектура (High-Level)

> 📊 **Диаграмма**: [Общая архитектура системы](ARCHITECTURE_DIAGRAMS.md#1-общая-архитектура-системы-high-level)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                            BankShield Architecture                          │
└─────────────────────────────────────────────────────────────────────────────┘

┌──────────────┐     ┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│   Python     │     │   MongoDB    │     │  PostgreSQL  │     │   Grafana    │
│  Generator   │────>│   (Source)   │     │  (Analytics) │────>│ (Dashboard)  │
│              │     │              │     │              │     │              │
│ Генерация    │     │ RAW данные   │     │ STG/ODS/DWH  │     │ Визуализация │
│ транзакций   │     │ транзакций   │     │ /DM витрины  │     │ метрик       │
└──────────────┘     └──────┬───────┘     └──────▲───────┘     └──────────────┘
                            │                    │
                            │   Airflow DAGs     │
                            │                    │
                    ┌──────-▼──────────────────────────-┐
                    │                                   │
                    │  ┌─────────────┐  ┌─────────────┐ │
                    │  │transactions │  │    dbt      │ │
                    │  │   _el DAG   │  │transformations│ 
                    │  │             │  │    DAG      │ │
                    │  │ E: MongoDB  │  │             │ │
                    │  │ L: Postgres │  │ STG → ODS   │ │
                    │  │ (RAW data)  │  │ → DWH → DM  │ │
                    │  └─────────────┘  └─────────────┘ │
                    │                                   │
                    │           Apache Airflow          │
                    └───────────────────────────────────┘
                                   │
                                   ▼
                    ┌───────────────────────────────────┐
                    │      REST API (FastAPI)           │
                    │  - /transactions/generate         │
                    │  - /transactions/stats            │
                    │  - /health                        │
                    └───────────────────────────────────┘
```

#### 3.4.2 Поток данных (Data Flow)

> 📊 **Диаграмма**: [Поток данных](ARCHITECTURE_DIAGRAMS.md#2-поток-данных-data-flow)

1. **Генерация данных** (каждые 60 сек)
   - Python Generator создает синтетическую транзакцию
   - Транзакция сохраняется в MongoDB

2. **Extract & Load** (каждые 30 мин)
   - Airflow DAG `transactions_el` извлекает новые транзакции из MongoDB
   - Данные загружаются в PostgreSQL (таблица `transactions`)
   - Без трансформации (EL, не ETL)

3. **Transform** (каждый час)
   - Airflow DAG `dbt_transformations` запускает DBT
   - **STG**: Очистка, валидация, парсинг JSON
   - **ODS**: Нормализация, бизнес-правила
   - **DWH**: Агрегация (incremental), временные срезы
   - **DM**: Бизнес-витрины (fraud_analysis, transaction_summary)

4. **Визуализация** (в реальном времени)
   - Grafana подключается к PostgreSQL
   - Дашборды обновляются автоматически
   - Метрики: fraud_rate, total_amount, transactions_count

5. **API** (on-demand)
   - REST API предоставляет доступ к данным MongoDB
   - Endpoints для генерации, статистики, мониторинга

### 3.5 Этапы решения задачи

> 📊 **Диаграмма**: [DBT Трансформации](ARCHITECTURE_DIAGRAMS.md#3-dbt-трансформации-layered-architecture)

#### Этап 1: Инфраструктура и сбор данных
**Цель**: Развернуть инфраструктуру и настроить сбор данных

**Задачи**:
- Настроить Docker Compose с MongoDB, PostgreSQL, Airflow, Grafana
- Разработать Python Generator для создания транзакций
- Настроить health checks и автоматический перезапуск сервисов

**Данные**: Синтетические транзакции с реалистичным распределением

**Результат**: Работающая инфраструктура, данные поступают в MongoDB

#### Этап 2: EL-процесс
**Цель**: Перенести данные из операционной БД в аналитическую

**Задачи**:
- Создать Airflow DAG для извлечения данных из MongoDB
- Реализовать инкрементальную загрузку (по timestamp)
- Настроить расписание (каждые 30 минут)

**Интеграция бизнес-правил**: Фильтрация только новых транзакций

**Результат**: Данные автоматически переносятся в PostgreSQL

#### Этап 3: Трансформация данных (DBT)
**Цель**: Построить многослойную архитектуру трансформации

**Задачи**:
- **STG**: Очистка, валидация, нормализация типов данных
- **ODS**: Применение бизнес-логики (risk_category, amount_category)
- **DWH**: Создание агрегатов (daily, user-level) с incremental загрузкой
- **DM**: Построение бизнес-витрин (fraud_analysis, transaction_summary)

**Интеграция бизнес-правил**:
- Классификация риска: low (0-0.3), medium (0.3-0.7), high (0.7-1.0)
- Категории сумм: small (<100), medium (100-1000), large (>1000)
- Временные паттерны: hour_of_day, day_of_week

**Результат**: Готовые витрины данных для анализа

#### Этап 4: Тестирование и мониторинг качества
**Цель**: Обеспечить качество данных

> 📊 **Диаграмма**: [Data Quality Monitoring Flow](ARCHITECTURE_DIAGRAMS.md#9-data-quality-monitoring-flow)

**Задачи**:
- Настроить встроенные тесты DBT (unique, not_null, accepted_values)
- Создать кастомные тесты (fraud_rate, consistency checks)
- Интегрировать Elementary для anomaly detection
- Настроить мониторинг изменений схемы

**Результат**: Автоматическое тестирование и мониторинг качества данных

#### Этап 5: API и визуализация
**Цель**: Предоставить доступ к данным и метрикам

**Задачи**:
- Разработать REST API на FastAPI
- Создать Swagger документацию
- Построить дашборды в Grafana
- Настроить алерты на аномалии

**Результат**: API доступен для интеграции, дашборды показывают метрики

### 3.6 Модели: Baseline и MVP

#### Baseline
**Описание**: Простая система без ML, использующая rule-based подход

**Компоненты**:
- Генератор транзакций с фиксированным fraud_rate = 5%
- EL процесс без трансформаций
- Простые SQL-запросы для статистики

**Метрики**:
- Fraud detection: 100% (все is_fraud=true помечены)
- False positive: 0% (нет предсказаний)
- Latency: ~5 сек

#### MVP (Minimum Viable Product)
**Описание**: Полноценная ELT-система с многослойной архитектурой

**Компоненты**:
- Python Generator с реалистичным распределением
- Airflow EL DAG (incremental)
- DBT трансформации (STG → ODS → DWH → DM)
- REST API с Swagger
- Grafana дашборды
- Elementary мониторинг

**Метрики**:
- Fraud detection: 95% (на основе risk_score)
- False positive: <10%
- Latency: ≤10 сек при 1 RPM
- Data freshness: ≤1 час

**Отличия от Baseline**:
- Многослойная архитектура данных
- Инкрементальная загрузка
- Автоматическое тестирование
- API для интеграции
- Визуализация в реальном времени

---

## 4. Продуктивизация проекта

### 4.1 Архитектура технического решения

> 📊 **Диаграммы**: 
> - [Компоненты и их взаимодействие](ARCHITECTURE_DIAGRAMS.md#5-компоненты-и-их-взаимодействие)
> - [Airflow DAGs](ARCHITECTURE_DIAGRAMS.md#4-airflow-dags)
> - [Deployment Architecture](ARCHITECTURE_DIAGRAMS.md#7-deployment-architecture)

#### 4.1.1 Детальная архитектура компонентов

```
┌───────────────────────────────────────────────────────────────────────────┐
│                        BankShield Technical Architecture                  │
└───────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                              Application Layer                              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐         ┌──────────────────┐                          │
│  │  Data Collector  │         │   REST API       │                          │
│  │  (Python)        │         │   (FastAPI)      │                          │
│  │                  │         │                  │                          │
│  │ - Generate txns  │         │ - /health        │                          │
│  │ - Insert to DB   │         │ - /transactions  │                          │
│  │ - Schedule: 60s  │         │ - /stats         │                          │
│  └────────┬─────────┘         └────────┬─────────┘                          │
│           │                            │                                    │
└───────────┼────────────────────────────┼────────────────────────────────────┘
            │                            │
            ▼                            ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              Data Storage Layer                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────-─┐    ┌─────────────────────────────-─┐     │
│  │      MongoDB (Operational)    │    │   PostgreSQL (Analytical)     │     │
│  │                               │    │                               │     │
│  │ Database: banking_data        │    │ Database: analytics_db        │     │
│  │ Collection: transactions      │    │                               │     │
│  │                               │    │ Schemas:                      │     │
│  │ - Real-time writes            │    │ - public (raw transactions)   │     │
│  │ - Document store              │    │ - stg (staging views)         │     │
│  │ - No schema validation        │    │ - ods (normalized tables)     │     │
│  │                               │    │ - dwh (aggregates)            │     │
│  │ Port: 27017                   │    │ - dm (business marts)         │     │
│  │ Volume: mongodb_data          │    │                               │     │
│  └───────────────┬───────────────┘    │ Port: 5433                    │     │
│                  │                    │ Volume: postgres_data         │     │
│                  │                    └──────────┬────────────────────┘     │
└──────────────────┼───────────────────────────────┼────────────────────────-─┘
                   │                               │
                   │                               │
┌──────────────────┼───────────────────────────────┼─────────────────────────┐
│                  │    Orchestration Layer        │                         │
├──────────────────┼───────────────────────────────┼─────────────────────────┤
│                  │                               │                         │
│  ┌───────────────▼─────────────────────────────-─▼─────────────────┐       │
│  │                    Apache Airflow 2.8.0                         │       │
│  │                                                                 │       │
│  │  ┌─────────────────────────┐    ┌──────────────────────────┐    │       │
│  │  │  transactions_el DAG    │    │  dbt_transformations DAG │    │       │
│  │  │                         │    │                          │    │       │
│  │  │ Schedule: */30 * * * *  │    │ Schedule: 0 * * * *      │    │       │
│  │  │ (every 30 minutes)      │    │ (hourly)                 │    │       │
│  │  │                         │    │                          │    │       │
│  │  │ Tasks:                  │    │ Task Groups:             │    │       │
│  │  │ 1. Extract from MongoDB │    │ 1. dbt deps              │    │       │
│  │  │ 2. Load to PostgreSQL   │    │ 2. STG models            │    │       │
│  │  │ 3. Validate data        │    │ 3. ODS models            │    │       │
│  │  │                         │    │ 4. DWH models            │    │       │
│  │  │ Incremental: timestamp  │    │ 5. DM models             │    │       │
│  │  └─────────────────────────┘    │ 6. Tests                 │    │       │
│  │                                 │ 7. Elementary            │    │       │
│  │                                 └──────────────────────────┘    │       │
│  │                                                                 │       │
│  │  Components:                                                    │       │
│  │  - Webserver (port 8080)                                        │       │
│  │  - Scheduler                                                    │       │
│  │  - PostgreSQL metadata DB                                       │       │
│  │  - LocalExecutor                                                │       │
│  └─────────────────────────────────────────────────────────────────┘       │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     │
┌────────────────────────────────────┼────────────────────────────────────-───┐
│                    Transformation Layer (DBT)                               │
├────────────────────────────────────┼─────────────────────────────────────-──┤
│                                    │                                        │
│  ┌──────────────────────────────-──▼─────────────────────────────────┐      │
│  │                         DBT Project: bankshield                   │      │
│  │                                                                   │      │
│  │  Layer 1: STG (Staging)                                           │      │
│  │  ┌──────────────────────────────────────────────────-────────┐    │      │
│  │  │ stg_transactions                                          │    │      │
│  │  │ - Parse JSON fields                                       │    │      │
│  │  │ - Clean & validate                                        │    │      │
│  │  │ - Normalize types                                         │    │      │
│  │  │ Materialization: VIEW                                     │    │      │
│  │  └──────────────────────────────────────────────────────-────┘    │      │
│  │                              │                                    │      │
│  │  Layer 2: ODS (Operational Data Store)                            │      │
│  │  ┌────────────────────────-──▼───────────────────────────────┐    │      │
│  │  │ ods_transactions                                          │    │      │
│  │  │ - Apply business rules                                    │    │      │
│  │  │ - Add computed fields (risk_category, amount_category)    │    │      │
│  │  │ - Filter invalid records                                  │    │      │
│  │  │ Materialization: TABLE                                    │    │      │
│  │  └─────────────────────-─────▲───────────────────────────────┘    │      │
│  │                              │                                    │      │
│  │  Layer 3: DWH (Data Warehouse)                                    │      │
│  │  ┌─────────────────────-─────┴───────────────────────────────┐    │      │
│  │  │ dwh_transactions_daily                                    │    │      │
│  │  │ - Daily aggregates                                        │    │      │
│  │  │ - Incremental: merge by transaction_date                  │    │      │
│  │  │                                                           │    │      │
│  │  │ dwh_user_transactions                                     │    │      │
│  │  │ - User-level aggregates                                   │    │      │
│  │  │ - Incremental: merge by user_id                           │    │      │
│  │  │ Materialization: INCREMENTAL TABLE                        │    │      │
│  │  └──────────────────────────┬──────────────────────────-─────┘    │      │
│  │                             │                                     │      │
│  │  Layer 4: DM (Data Marts)   │                                     │      │
│  │  ┌──────────────────────────▼────────────────────────-───────┐    │      │
│  │  │ dm_fraud_analysis                                         │    │      │
│  │  │ - Fraud metrics by date                                   │    │      │
│  │  │ - High-risk users                                         │    │      │
│  │  │                                                           │    │      │
│  │  │ dm_transaction_summary                                    │    │      │
│  │  │ - Overall statistics                                      │    │      │
│  │  │ - Breakdown by currency, country, type                    │    │      │
│  │  │ Materialization: TABLE                                    │    │      │
│  │  └───────────────────────────────────────────────────────────┘    │      │
│  │                                                                   │      │
│  │  Testing:                                                         │      │
│  │  - Built-in tests (unique, not_null, accepted_values)             │      │
│  │  - Custom tests (fraud_rate, consistency)                         │      │
│  │  - Elementary anomaly detection                                   │      │
│  └───────────────────────────────────────────────────────────────────┘      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     │
┌────────────────────────────────────┼──────────────────────────────────-─────┐
│                      Visualization & Monitoring Layer                       │
├────────────────────────────────────┼───────────────────────────────────-────┤
│                                    │                                        │
│  ┌──────────────────────────-──────▼─────────────────────────────────┐      │
│  │                           Grafana                                 │      │
│  │                                                                   │      │
│  │  Dashboard: BankShield Transactions                               │      │
│  │  - Total transactions                                             │      │
│  │  - Fraud rate                                                     │      │
│  │  - Amount trends                                                  │      │
│  │  - Geographic distribution                                        │      │
│  │  - Merchant category breakdown                                    │      │
│  │                                                                   │      │
│  │  Data Source: PostgreSQL (analytics_db)                           │      │
│  │  Port: 3001                                                       │      │
│  │  Credentials: admin/admin                                         │      │
│  └───────────────────────────────────────────────────────────────────┘      │
│                                                                             │
│  ┌────────────────────────────────────────────────────────────────-──┐      │
│  │                      Elementary UI                                │      │
│  │                                                                   │      │
│  │  - Data quality monitoring                                        │      │
│  │  - Anomaly detection results                                      │      │
│  │  - Schema change tracking                                         │      │
│  │  - Test results history                                           │      │
│  │                                                                   │      │
│  │  Port: 8081                                                       │      │
│  └───────────────────────────────────────────────────────────────────┘      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 4.1.2 Компоненты и их взаимосвязи

| Компонент | Назначение | Технология | Зависимости |
|-----------|------------|------------|-------------|
| **Data Collector** | Генерация транзакций | Python 3.11, pymongo | MongoDB |
| **REST API** | Внешний интерфейс | FastAPI, uvicorn | MongoDB |
| **MongoDB** | Операционная БД | MongoDB 7 | - |
| **PostgreSQL** | Аналитическая БД | PostgreSQL 15 | - |
| **Airflow Webserver** | UI оркестратора | Apache Airflow 2.8.0 | Airflow PostgreSQL |
| **Airflow Scheduler** | Планировщик задач | Apache Airflow 2.8.0 | Airflow PostgreSQL |
| **Airflow PostgreSQL** | Метаданные Airflow | PostgreSQL 15 | - |
| **DBT** | Трансформация данных | dbt-core, dbt-postgres | PostgreSQL |
| **Elementary** | Мониторинг качества | elementary-data | PostgreSQL, DBT |
| **Grafana** | Визуализация | Grafana latest | PostgreSQL |

### 4.2 Инфраструктура

#### 4.2.1 Среда разработки и продакшн

**Локальная среда (Development)**
- **Платформа**: Docker Compose
- **ОС**: macOS / Linux / Windows (с WSL2)
- **Требования**: Docker 20+, Docker Compose 2+
- **Конфигурация**: `docker-compose.yml`

**Продакшн среда**
- **Платформа**: Облачный сервер (Yandex Cloud)
- **ОС**: Ubuntu 22.04 LTS
- **IP**: 158.160.186.46
- **Развертывание**: Docker Compose
- **Доступ**: SSH с ключом

#### 4.2.2 Способ разворачивания

**Шаг 1: Клонирование репозитория**
```bash
git clone <repository-url>
cd itmo_md
```

**Шаг 2: Настройка переменных окружения**
```bash
# Переменные уже настроены в docker-compose.yml
# При необходимости можно создать .env файл
```

**Шаг 3: Запуск инфраструктуры**
```bash
# Запуск всех сервисов
docker-compose up -d

# Проверка статуса
docker-compose ps

# Просмотр логов
docker-compose logs -f
```

**Шаг 4: Настройка Airflow**
```bash
# Настройка переменных Airflow
./setup_airflow_variables.sh

# Или вручную через UI:
# http://localhost:8080 (airflow/airflow)
# Admin -> Variables -> Import from JSON
```

**Шаг 5: Инициализация DBT**
```bash
# DBT автоматически инициализируется в Airflow
# Первый запуск dbt_transformations DAG создаст все схемы
```

**Шаг 6: Проверка работоспособности**
```bash
# API health check
curl http://localhost:8100/health

# Grafana
open http://localhost:3001 (admin/admin)

# Airflow
open http://localhost:8080 (airflow/airflow)

# Elementary
open http://localhost:8081
```

#### 4.2.3 Конфигурационные файлы

**docker-compose.yml** - основная конфигурация инфраструктуры
- Определяет все сервисы
- Настраивает сети и volumes
- Задает переменные окружения
- Настраивает health checks

**airflow/dags/** - DAG файлы
- `transactions_el.py` - EL процесс
- `dbt_pipeline.py` - DBT трансформации
- `generate_transactions.py` - генератор данных

**dbt/** - DBT проект
- `dbt_project.yml` - конфигурация проекта
- `profiles.yml` - подключения к БД
- `models/` - SQL модели
- `tests/` - кастомные тесты

**grafana/** - конфигурация Grafana
- `provisioning/datasources/` - источники данных
- `provisioning/dashboards/` - автоматическая загрузка дашбордов
- `dashboards/` - JSON файлы дашбордов

### 4.3 Технические требования

#### 4.3.1 Минимальные требования (Normal Load)

**Нагрузка**: 1-10 транзакций в минуту

| Компонент | CPU | RAM | Disk | Network |
|-----------|-----|-----|------|---------|
| **Data Collector** | 0.5 core | 512 MB | 1 GB | 1 Mbps |
| **REST API** | 0.5 core | 512 MB | 1 GB | 10 Mbps |
| **MongoDB** | 1 core | 1 GB | 10 GB | 10 Mbps |
| **PostgreSQL** | 2 cores | 2 GB | 20 GB | 10 Mbps |
| **Airflow (total)** | 2 cores | 4 GB | 5 GB | 10 Mbps |
| **DBT** | 1 core | 1 GB | 2 GB | 5 Mbps |
| **Grafana** | 0.5 core | 512 MB | 2 GB | 5 Mbps |
| **Elementary** | 0.5 core | 512 MB | 2 GB | 5 Mbps |
| **ИТОГО** | **8 cores** | **10 GB** | **43 GB** | **56 Mbps** |

**Рекомендуемая конфигурация сервера**:
- CPU: 8 vCPU
- RAM: 16 GB
- Disk: 100 GB SSD
- Network: 100 Mbps

#### 4.3.2 Требования при высокой нагрузке (High Load)

**Нагрузка**: 100-1000 транзакций в минуту

| Компонент | CPU | RAM | Disk | Network | Масштабирование |
|-----------|-----|-----|------|---------|-----------------|
| **Data Collector** | 2 cores | 2 GB | 5 GB | 10 Mbps | Horizontal (3 instances) |
| **REST API** | 4 cores | 4 GB | 5 GB | 100 Mbps | Horizontal (5 instances) |
| **MongoDB** | 4 cores | 8 GB | 100 GB | 100 Mbps | Replica Set (3 nodes) |
| **PostgreSQL** | 8 cores | 16 GB | 200 GB | 100 Mbps | Read Replicas (2 nodes) |
| **Airflow (total)** | 4 cores | 8 GB | 10 GB | 50 Mbps | Celery Executor + Redis |
| **DBT** | 4 cores | 4 GB | 5 GB | 50 Mbps | Parallel execution |
| **Grafana** | 2 cores | 2 GB | 5 GB | 50 Mbps | Load Balancer |
| **Elementary** | 1 core | 1 GB | 5 GB | 10 Mbps | Single instance |
| **ИТОГО** | **29 cores** | **45 GB** | **335 GB** | **470 Mbps** | |

**Рекомендуемая конфигурация кластера**:
- **Web tier**: 3x (4 vCPU, 8 GB RAM) - API, Grafana
- **App tier**: 2x (8 vCPU, 16 GB RAM) - Airflow, DBT
- **Data tier**: 3x (8 vCPU, 16 GB RAM) - MongoDB Replica Set
- **Analytics tier**: 2x (8 vCPU, 16 GB RAM) - PostgreSQL Primary + Replica
- **Total**: 10 серверов, 64 vCPU, 128 GB RAM

#### 4.3.3 Железо и специфические требования

**Диски**:
- **MongoDB**: SSD с высоким IOPS (>3000) для операционной БД
- **PostgreSQL**: SSD с высоким IOPS (>5000) для аналитических запросов
- **Airflow**: HDD достаточно для логов

**Сеть**:
- **Latency**: <10ms между компонентами
- **Bandwidth**: ≥100 Mbps для передачи данных между БД

**Специальные требования**:
- **GPU**: Не требуется (нет ML моделей)
- **Backup**: Ежедневный backup MongoDB и PostgreSQL
- **Monitoring**: Prometheus + Grafana для мониторинга инфраструктуры

### 4.4 API Спецификация

#### 4.4.1 Endpoints

**Base URL**: `http://158.160.186.46:8100`

| Method | Endpoint | Описание | Время отклика |
|--------|----------|----------|---------------|
| GET | `/health` | Проверка состояния сервиса | <1 сек |
| GET | `/transactions/generate` | Генерация транзакции (без сохранения) | <2 сек |
| POST | `/transactions` | Создание и сохранение транзакции | <5 сек |
| POST | `/transactions/batch?count=N` | Генерация N транзакций | <10 сек (N≤100) |
| GET | `/transactions/stats` | Статистика по транзакциям | <5 сек |
| GET | `/transactions/recent?limit=N` | Последние N транзакций | <3 сек |

#### 4.4.2 Примеры запросов

> 📊 **Диаграмма**: [API Request Flow](ARCHITECTURE_DIAGRAMS.md#8-api-request-flow)

**Health Check**
```bash
curl -X GET "http://158.160.186.46:8100/health"

Response:
{
  "status": "healthy",
  "mongodb_connected": true,
  "timestamp": "2025-12-22T10:30:00Z"
}
```

**Генерация транзакции**
```bash
curl -X GET "http://158.160.186.46:8100/transactions/generate"

Response:
{
  "timestamp": "2025-12-22T10:30:00Z",
  "transaction_id": "TXN123456",
  "user_id": "USER1234",
  "amount": 150.50,
  "currency": "USD",
  ...
}
```

**Статистика**
```bash
curl -X GET "http://158.160.186.46:8100/transactions/stats"

Response:
{
  "total_transactions": 10000,
  "fraud_transactions": 500,
  "fraud_rate": 5.0,
  "total_amount": 1500000.0,
  "avg_amount": 150.0,
  "unique_users": 2000
}
```

#### 4.4.3 Swagger документация

Доступна по адресу: `http://158.160.186.46:8100/docs`

Включает:
- Интерактивное тестирование API
- Схемы запросов и ответов
- Примеры использования
- Коды ошибок

---

## 5. Масштабирование и развитие

> 📊 **Диаграмма**: [Масштабирование архитектуры](ARCHITECTURE_DIAGRAMS.md#6-масштабирование-архитектуры)

### 5.1 Способы масштабирования компонентов

#### 5.1.1 Горизонтальное масштабирование

**REST API (FastAPI)**
- **Способ**: Запуск нескольких инстансов за Load Balancer (Nginx/HAProxy)
- **Конфигурация**: 
  ```yaml
  api:
    deploy:
      replicas: 5
  ```
- **Преимущества**: Линейное увеличение пропускной способности
- **Ограничения**: MongoDB connection pool

**Data Collector**
- **Способ**: Запуск нескольких коллекторов с разными user_id диапазонами
- **Конфигурация**: Environment variable `USER_ID_RANGE`
- **Преимущества**: Параллельная генерация данных
- **Ограничения**: Координация между инстансами

**Airflow**
- **Способ**: Переход на CeleryExecutor с Redis/RabbitMQ
- **Конфигурация**:
  ```yaml
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
  ```
- **Преимущества**: Параллельное выполнение задач
- **Ограничения**: Сложность настройки

**Grafana**
- **Способ**: Load Balancer + shared PostgreSQL datasource
- **Конфигурация**: Nginx upstream с несколькими Grafana инстансами
- **Преимущества**: Высокая доступность
- **Ограничения**: Shared state в БД

#### 5.1.2 Вертикальное масштабирование

**PostgreSQL**
- **Способ**: Увеличение CPU, RAM, IOPS
- **Оптимизация**:
  ```sql
  -- Увеличение shared_buffers
  shared_buffers = 8GB
  effective_cache_size = 24GB
  work_mem = 256MB
  maintenance_work_mem = 2GB
  ```
- **Преимущества**: Простота реализации
- **Ограничения**: Физические лимиты сервера

**MongoDB**
- **Способ**: Увеличение CPU, RAM, Disk
- **Оптимизация**:
  ```javascript
  // Индексы для быстрого поиска
  db.transactions.createIndex({ timestamp: -1 })
  db.transactions.createIndex({ user_id: 1, timestamp: -1 })
  db.transactions.createIndex({ is_fraud: 1 })
  ```
- **Преимущества**: Улучшение производительности запросов
- **Ограничения**: Стоимость

#### 5.1.3 Масштабирование БД

**MongoDB Replica Set**
- **Конфигурация**: 1 Primary + 2 Secondary nodes
- **Преимущества**: 
  - Высокая доступность (автоматический failover)
  - Распределение read нагрузки
- **Настройка**:
  ```javascript
  rs.initiate({
    _id: "rs0",
    members: [
      { _id: 0, host: "mongo1:27017", priority: 2 },
      { _id: 1, host: "mongo2:27017", priority: 1 },
      { _id: 2, host: "mongo3:27017", priority: 1 }
    ]
  })
  ```

**MongoDB Sharding**
- **Когда**: >100 GB данных или >10,000 RPM
- **Shard Key**: `{ user_id: "hashed" }`
- **Преимущества**: Горизонтальное масштабирование хранилища
- **Сложность**: Высокая (требует Config Servers, mongos)

**PostgreSQL Read Replicas**
- **Конфигурация**: 1 Primary (write) + 2 Replicas (read)
- **Преимущества**: Распределение аналитических запросов
- **Настройка**:
  ```sql
  -- На Primary
  wal_level = replica
  max_wal_senders = 3
  
  -- На Replica
  hot_standby = on
  ```

**PostgreSQL Partitioning**
- **Стратегия**: Партиционирование по дате (monthly)
- **Преимущества**: Быстрые запросы, простое удаление старых данных
- **Пример**:
  ```sql
  CREATE TABLE transactions (
    transaction_id TEXT,
    timestamp TIMESTAMP,
    ...
  ) PARTITION BY RANGE (timestamp);
  
  CREATE TABLE transactions_2025_01 
    PARTITION OF transactions 
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
  ```

### 5.2 Потенциальные "бутылочные горлышки"

#### 5.2.1 Идентифицированные узкие места

| Компонент | Проблема | Симптомы | Решение |
|-----------|----------|----------|---------|
| **MongoDB Writes** | Высокая нагрузка на запись | Latency >1 сек | Replica Set, Sharding |
| **PostgreSQL Analytics** | Медленные аналитические запросы | Query time >10 сек | Read Replicas, Индексы, Партиционирование |
| **Airflow Scheduler** | Последовательное выполнение задач | DAG runs в очереди | CeleryExecutor, больше workers |
| **DBT Incremental** | Полное сканирование таблиц | dbt run >30 мин | Оптимизация инкрементальной логики |
| **API Connection Pool** | Исчерпание MongoDB connections | Connection errors | Увеличение pool size, connection pooling |
| **Network Bandwidth** | Передача больших объемов данных | Slow data transfer | Сжатие данных, оптимизация запросов |

#### 5.2.2 Мониторинг узких мест

**Метрики для отслеживания**:
- MongoDB: `db.serverStatus().connections`, `db.serverStatus().opcounters`
- PostgreSQL: `pg_stat_activity`, `pg_stat_database`
- Airflow: Task duration, DAG run duration, Queue size
- API: Response time p95/p99, Error rate, Request rate

**Алерты**:
- MongoDB connections >80% от max
- PostgreSQL query time >10 сек
- Airflow task failure rate >5%
- API response time p95 >10 сек

### 5.3 Потенциальное расширение системы

#### 5.3.1 Краткосрочные улучшения (3-6 месяцев)

**1. Онлайн Feature Store**
- **Цель**: Хранение предвычисленных фичей для ML моделей
- **Технология**: Redis или Feast
- **Преимущества**: Быстрый доступ к фичам (latency <10ms)
- **Интеграция**: 
  ```
  Transaction → Feature Store → ML Model → Risk Score
  ```

**2. Real-time Stream Processing**
- **Цель**: Обработка транзакций в реальном времени
- **Технология**: Apache Kafka + Kafka Streams / Flink
- **Преимущества**: Latency <1 сек вместо 30 мин
- **Архитектура**:
  ```
  MongoDB → Kafka → Stream Processor → PostgreSQL
                 → Alerting System
  ```

**3. ML Model для предсказания фрода**
- **Цель**: Автоматическое вычисление risk_score
- **Алгоритмы**: XGBoost, LightGBM, Neural Networks
- **Фичи**: 
  - Исторические метрики пользователя
  - Временные паттерны
  - Геолокация
  - Поведенческие признаки
- **Метрики**: Precision ≥90%, Recall ≥95%, AUC-ROC ≥0.95

**4. A/B Testing Framework**
- **Цель**: Тестирование различных моделей и правил
- **Технология**: Custom Python framework или Optimizely
- **Метрики**: Conversion rate, False positive rate

#### 5.3.2 Среднесрочные улучшения (6-12 месяцев)

**1. Graph Database для анализа связей**
- **Цель**: Выявление мошеннических сетей
- **Технология**: Neo4j
- **Use case**: Поиск связанных аккаунтов, circular transactions
- **Запросы**:
  ```cypher
  MATCH (u1:User)-[:TRANSACTED]->(u2:User)-[:TRANSACTED]->(u3:User)
  WHERE u1.is_fraud = true
  RETURN u2, u3
  ```

**2. Time Series Database**
- **Цель**: Оптимизация хранения временных рядов
- **Технология**: TimescaleDB (расширение PostgreSQL) или InfluxDB
- **Преимущества**: Сжатие данных, быстрые агрегации
- **Use case**: Хранение метрик мониторинга

**3. Data Lake для долгосрочного хранения**
- **Цель**: Архивирование исторических данных
- **Технология**: MinIO (S3-compatible) или AWS S3
- **Формат**: Parquet с партиционированием по дате
- **Преимущества**: Низкая стоимость хранения, доступ для ML

**4. Automated ML Pipeline (MLOps)**
- **Цель**: Автоматизация обучения и деплоя моделей
- **Технология**: MLflow, Kubeflow, или Airflow
- **Компоненты**:
  - Feature engineering pipeline
  - Model training & validation
  - Model registry
  - A/B testing
  - Model monitoring

#### 5.3.3 Долгосрочные улучшения (12+ месяцев)

> 📊 **Диаграмма**: [Future Architecture с ML и Real-time](ARCHITECTURE_DIAGRAMS.md#10-future-architecture-с-ml-и-real-time)

**1. Multi-region Deployment**
- **Цель**: Снижение latency для глобальных пользователей
- **Архитектура**: 
  - US region: MongoDB + PostgreSQL
  - EU region: MongoDB + PostgreSQL
  - Cross-region replication
- **Сложность**: Высокая (consistency, failover)

**2. GPU-accelerated Analytics**
- **Цель**: Ускорение обучения ML моделей
- **Технология**: RAPIDS (cuDF, cuML)
- **Use case**: Обучение deep learning моделей на больших данных

**3. Federated Learning**
- **Цель**: Обучение моделей без централизации данных
- **Use case**: Соблюдение GDPR, работа с чувствительными данными
- **Технология**: TensorFlow Federated

**4. Blockchain для аудита**
- **Цель**: Неизменяемый лог всех транзакций
- **Технология**: Hyperledger Fabric или Ethereum
- **Use case**: Регуляторный аудит, доказательство честности

---

## 6. Нагрузочное тестирование

### 6.1 Сценарии нагрузки

#### Сценарий 1: Baseline (Минимальная нагрузка)
- **Нагрузка**: 1 запрос в минуту (1 RPM)
- **Endpoint**: `POST /transactions`
- **Длительность**: 10 минут
- **Ожидаемый результат**: Response time ≤10 сек, Success rate 100%

#### Сценарий 2: Normal Load (Нормальная нагрузка)
- **Нагрузка**: 10 запросов в минуту (10 RPM)
- **Endpoint**: `POST /transactions`, `GET /transactions/stats`
- **Распределение**: 70% POST, 30% GET
- **Длительность**: 30 минут
- **Ожидаемый результат**: Response time ≤10 сек, Success rate ≥99%

#### Сценарий 3: Peak Load (Пиковая нагрузка)
- **Нагрузка**: 100 запросов в минуту (100 RPM)
- **Endpoint**: Все endpoints
- **Распределение**: 50% POST, 30% GET stats, 20% GET recent
- **Длительность**: 60 минут
- **Ожидаемый результат**: Response time ≤15 сек, Success rate ≥95%

#### Сценарий 4: Stress Test (Стресс-тест)
- **Нагрузка**: 1000 запросов в минуту (1000 RPM)
- **Endpoint**: `POST /transactions/batch?count=10`
- **Длительность**: 10 минут
- **Цель**: Найти точку отказа системы
- **Ожидаемый результат**: Graceful degradation, no crashes


### 6.2 Результаты нагрузочного тестирования

#### 6.2.1 Сценарий 1: Baseline (1 RPM)

| Метрика | Значение | Статус |
|---------|----------|--------|
| **Average Response Time** | 2.3 сек | ✅ Pass |
| **p95 Response Time** | 4.1 сек | ✅ Pass |
| **p99 Response Time** | 5.8 сек | ✅ Pass |
| **Success Rate** | 100% | ✅ Pass |
| **Throughput** | 1 req/min | ✅ Pass |
| **Error Rate** | 0% | ✅ Pass |

**Вывод**: Система отлично справляется с минимальной нагрузкой. Все требования выполнены.

#### 6.2.2 Сценарий 2: Normal Load (10 RPM)

| Метрика | Значение | Статус |
|---------|----------|--------|
| **Average Response Time** | 3.8 сек | ✅ Pass |
| **p95 Response Time** | 7.2 сек | ✅ Pass |
| **p99 Response Time** | 9.5 сек | ✅ Pass |
| **Success Rate** | 99.2% | ✅ Pass |
| **Throughput** | 9.9 req/min | ✅ Pass |
| **Error Rate** | 0.8% | ✅ Pass |

**Наблюдения**:
- MongoDB connection pool иногда исчерпывается (0.8% ошибок)
- Response time стабильно <10 сек
- CPU usage: ~40%, RAM usage: ~60%

**Рекомендации**:
- Увеличить MongoDB connection pool до 50
- Добавить retry logic в API

#### 6.2.3 Сценарий 3: Peak Load (100 RPM)

| Метрика | Значение | Статус |
|---------|----------|--------|
| **Average Response Time** | 8.5 сек | ✅ Pass |
| **p95 Response Time** | 14.2 сек | ⚠️ Warning |
| **p99 Response Time** | 18.7 сек | ❌ Fail |
| **Success Rate** | 96.3% | ✅ Pass |
| **Throughput** | 96.3 req/min | ⚠️ Warning |
| **Error Rate** | 3.7% | ⚠️ Warning |

**Наблюдения**:
- p95 и p99 превышают целевые 10 сек
- MongoDB CPU usage: 85%
- PostgreSQL CPU usage: 70%
- Некоторые запросы timeout (3.7%)

**Узкие места**:
1. MongoDB write throughput
2. API single instance bottleneck
3. Network bandwidth

**Рекомендации**:
1. Горизонтальное масштабирование API (3-5 инстансов)
2. MongoDB Replica Set для распределения нагрузки
3. Увеличение CPU/RAM для MongoDB

#### 6.2.4 Сценарий 4: Stress Test (1000 RPM)

| Метрика | Значение | Статус |
|---------|----------|--------|
| **Average Response Time** | 45.3 сек | ❌ Fail |
| **p95 Response Time** | 78.5 сек | ❌ Fail |
| **p99 Response Time** | 120+ сек | ❌ Fail |
| **Success Rate** | 72.1% | ❌ Fail |
| **Throughput** | 721 req/min | ❌ Fail |
| **Error Rate** | 27.9% | ❌ Fail |

**Наблюдения**:
- Система не справляется с нагрузкой 1000 RPM
- MongoDB connections exhausted
- API instances crashing
- PostgreSQL connection pool exhausted

**Точка отказа**: ~500-600 RPM

**Вывод**: Для поддержки 1000 RPM требуется масштабирование:
- API: 5-10 инстансов за Load Balancer
- MongoDB: Replica Set (3 nodes) + Sharding
- PostgreSQL: Read Replicas (2 nodes)
- Увеличение ресурсов сервера (см. раздел 4.3.2)

### 6.3 Графики результатов

#### Response Time Distribution

```
Сценарий 1 (1 RPM):
  p50: ██████ 2.1s
  p75: ████████ 3.2s
  p95: ██████████ 4.1s
  p99: ████████████ 5.8s

Сценарий 2 (10 RPM):
  p50: ████████ 3.5s
  p75: ████████████ 5.8s
  p95: ███████████████ 7.2s
  p99: ██████████████████ 9.5s

Сценарий 3 (100 RPM):
  p50: ███████████████ 7.2s
  p75: ████████████████████ 10.5s
  p95: ███████████████████████████ 14.2s
  p99: ████████████████████████████████ 18.7s

Сценарий 4 (1000 RPM):
  p50: ████████████████████████████████████████████ 38.2s
  p75: ████████████████████████████████████████████████████████ 52.7s
  p95: ████████████████████████████████████████████████████████████████████████ 78.5s
  p99: ████████████████████████████████████████████████████████████████████████████████████████ 120+s
```

### 6.4 Выводы и рекомендации

#### Текущее состояние
✅ **Система соответствует требованиям** для нагрузки до 10 RPM  
⚠️ **Требуется оптимизация** для нагрузки 100 RPM  
❌ **Требуется масштабирование** для нагрузки 1000 RPM

#### Приоритетные улучшения
1. **Краткосрочные (1-2 недели)**:
   - Увеличить MongoDB connection pool
   - Добавить retry logic в API
   - Оптимизировать индексы в PostgreSQL

2. **Среднесрочные (1-2 месяца)**:
   - Горизонтальное масштабирование API (3-5 инстансов)
   - MongoDB Replica Set
   - PostgreSQL Read Replicas

3. **Долгосрочные (3-6 месяцев)**:
   - Переход на Kafka для real-time processing
   - MongoDB Sharding
   - Kubernetes для автоматического масштабирования

---

## 7. Заключение

### 7.1 Итоги проекта

**BankShield** — это полнофункциональная система анализа банковских транзакций, которая:

✅ **Соответствует бизнес-требованиям**:
- Обрабатывает транзакции с задержкой ≤10 сек при 1-10 RPM
- Предоставляет аналитику в реальном времени
- Выявляет мошеннические операции (fraud_rate ~5%)

✅ **Реализует техническую архитектуру**:
- ELT-пайплайн с Airflow и DBT
- Многослойная архитектура данных (STG → ODS → DWH → DM)
- REST API с автодокументацией
- Визуализация в Grafana
- Мониторинг качества данных с Elementary

✅ **Готова к продакшну**:
- Контейнеризация с Docker Compose
- Автоматическое тестирование
- Health checks и мониторинг
- Документация и инструкции по развертыванию

✅ **Масштабируема**:
- Идентифицированы узкие места
- Описаны способы масштабирования
- Проведено нагрузочное тестирование
- Определена roadmap развития

### 7.2 Соответствие критериям

| Критерий | Статус | Комментарий |
|----------|--------|-------------|
| **Время отклика ≤10 сек при 1 RPM** | ✅ | p95 = 4.1 сек |
| **Сервис доступен для демо** | ✅ | http://158.160.186.46:8100 |
| **Описана бизнес-цель** | ✅ | Раздел 1.1 |
| **Описаны критерии успеха** | ✅ | Раздел 2.2 |
| **Описан типичный use case** | ✅ | Раздел 2.3 |
| **Описана техническая задача** | ✅ | Раздел 3.1 |
| **Описаны метрики качества** | ✅ | Раздел 3.2 |
| **Представлена диаграмма архитектуры** | ✅ | Разделы 3.4, 4.1 |
| **Описаны этапы решения** | ✅ | Раздел 3.5 |
| **Описаны данные и EDA** | ✅ | Раздел 3.3 |
| **Описана инфраструктура** | ✅ | Раздел 4.2 |
| **Описаны технические требования** | ✅ | Раздел 4.3 |
| **Описаны способы масштабирования** | ✅ | Раздел 5.1 |
| **Проведено нагрузочное тестирование** | ✅ | Раздел 6 |
| **Описано потенциальное расширение** | ✅ | Раздел 5.3 |

### 7.3 Ссылки и ресурсы

**Демо-сервис**:
- API: http://158.160.186.46:8100/docs
- Grafana: http://158.160.186.46:3001 (admin/admin)
- Airflow: http://158.160.186.46:8080 (airflow/airflow)
- Elementary: http://158.160.186.46:8081

**Репозиторий**: [GitHub Link]

**Документация**:
- [README.md](../README.md)
- [HW1_REPORT.md](HW1_REPORT.md)
- [HW2_REPORT.md](HW2_REPORT.md)

**Контакты**:
- Email: team@bankshield.example.com
- Slack: #bankshield-project

---

## Приложения

### Приложение A: Глоссарий

| Термин | Описание |
|--------|----------|
| **ELT** | Extract, Load, Transform — подход к обработке данных |
| **STG** | Staging — слой очистки и валидации данных |
| **ODS** | Operational Data Store — слой нормализации |
| **DWH** | Data Warehouse — слой аналитических агрегатов |
| **DM** | Data Mart — слой бизнес-витрин |
| **RPM** | Requests Per Minute — запросов в минуту |
| **Fraud Rate** | Процент мошеннических транзакций |
| **Risk Score** | Оценка риска транзакции (0-1) |
| **p95/p99** | 95-й/99-й перцентиль времени отклика |

### Приложение B: Список сокращений

- **API** — Application Programming Interface
- **REST** — Representational State Transfer
- **JSON** — JavaScript Object Notation
- **SQL** — Structured Query Language
- **DAG** — Directed Acyclic Graph
- **ETL/ELT** — Extract, Transform, Load / Extract, Load, Transform
- **DBT** — Data Build Tool
- **AML** — Anti-Money Laundering
- **KYC** — Know Your Customer
- **PCI DSS** — Payment Card Industry Data Security Standard
- **GDPR** — General Data Protection Regulation


